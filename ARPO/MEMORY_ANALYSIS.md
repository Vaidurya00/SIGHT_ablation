# 显存占用分析：使用 Worker 模型 vs 重新加载模型

## 显存占用对比

### 之前的方式（重新加载模型）

```python
# 从路径重新加载一个完整的模型
self.mi_model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map="auto",
    torch_dtype=torch.float16
)
```

**显存占用：**
- 额外加载一个完整的模型实例
- 对于 3B 模型（fp16）：约 **6-8GB** 额外显存
- 对于 7B 模型（fp16）：约 **14-16GB** 额外显存
- 这是**完全额外的显存占用**

### 现在的方式（使用 Worker 中的模型）

```python
# 使用 worker 中已有的模型（只是引用）
self.mi_model = self.worker.actor_module_fsdp  # 或 ref_module_fsdp
```

**显存占用：**
- **不额外占用显存**（只是引用，不是复制）
- 模型已经在显存中了（用于训练或 ref log prob 计算）
- FSDP 模型是分片的，每个 GPU 只持有模型的一部分

## 详细分析

### 1. 模型引用 vs 模型复制

- **引用**：`self.mi_model = self.worker.actor_module_fsdp` 只是创建一个引用，不复制模型参数
- **复制**：如果使用 `copy.deepcopy()` 或重新加载，才会额外占用显存

### 2. FSDP 分片模型

FSDP 模型的特点：
- 每个 GPU rank 只持有模型参数的一部分（分片）
- 例如 4 个 GPU，每个 GPU 只持有 1/4 的模型参数
- 在 forward 时，FSDP 会自动处理通信和参数收集
- **不会额外占用显存**，因为参数已经在显存中了

### 3. 临时显存峰值

在计算 MI 时：
- 需要 forward 两次（prior 和 posterior）
- 可能会产生一些**临时的激活值显存**
- 但这是正常的，计算完成后会自动释放
- 相比重新加载整个模型，这个临时峰值要小得多

## 显存占用对比表

| 方式 | 模型参数显存 | 激活值显存 | 总额外显存 |
|------|------------|-----------|-----------|
| **之前（重新加载）** | 6-8GB (3B) | ~0.5GB | **6.5-8.5GB** |
| **现在（引用）** | 0GB (已存在) | ~0.5GB | **~0.5GB** |

**节省显存：约 6-8GB（对于 3B 模型）**

## 注意事项

### 1. 模型状态管理

使用 FSDP 模型时需要注意：
- 模型可能处于训练模式（`train()`）或评估模式（`eval()`）
- 代码中已经设置了 `self.mi_model.eval()`，这是正确的

### 2. 设备一致性

- FSDP 模型会自动处理设备分配
- 输入数据需要放在正确的设备上
- 代码中已经正确处理了设备分配

### 3. 并发使用

如果同时进行：
- Actor 模型训练
- MI 计算（使用同一个 actor 模型）

可能会有一些显存竞争，但这是正常的，因为：
- 训练和 MI 计算不会同时进行（MI 计算在 rollout 阶段）
- FSDP 会自动管理参数的分片和通信

## 结论

✅ **使用 Worker 中的模型不会比之前占用更多显存**

实际上：
- **节省显存**：不重复加载模型，节省 6-8GB（3B 模型）
- **提高效率**：不需要重新加载模型，节省时间
- **保持一致性**：使用与训练相同的模型，结果更一致

## 建议

1. **优先使用 actor 模型**：如果可用，优先使用 `actor_module_fsdp`
2. **回退机制**：如果 worker 中没有模型，自动回退到从路径加载
3. **监控显存**：在训练过程中监控显存使用，确保没有意外峰值


## 显存占用对比

### 之前的方式（重新加载模型）

```python
# 从路径重新加载一个完整的模型
self.mi_model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map="auto",
    torch_dtype=torch.float16
)
```

**显存占用：**
- 额外加载一个完整的模型实例
- 对于 3B 模型（fp16）：约 **6-8GB** 额外显存
- 对于 7B 模型（fp16）：约 **14-16GB** 额外显存
- 这是**完全额外的显存占用**

### 现在的方式（使用 Worker 中的模型）

```python
# 使用 worker 中已有的模型（只是引用）
self.mi_model = self.worker.actor_module_fsdp  # 或 ref_module_fsdp
```

**显存占用：**
- **不额外占用显存**（只是引用，不是复制）
- 模型已经在显存中了（用于训练或 ref log prob 计算）
- FSDP 模型是分片的，每个 GPU 只持有模型的一部分

## 详细分析

### 1. 模型引用 vs 模型复制

- **引用**：`self.mi_model = self.worker.actor_module_fsdp` 只是创建一个引用，不复制模型参数
- **复制**：如果使用 `copy.deepcopy()` 或重新加载，才会额外占用显存

### 2. FSDP 分片模型

FSDP 模型的特点：
- 每个 GPU rank 只持有模型参数的一部分（分片）
- 例如 4 个 GPU，每个 GPU 只持有 1/4 的模型参数
- 在 forward 时，FSDP 会自动处理通信和参数收集
- **不会额外占用显存**，因为参数已经在显存中了

### 3. 临时显存峰值

在计算 MI 时：
- 需要 forward 两次（prior 和 posterior）
- 可能会产生一些**临时的激活值显存**
- 但这是正常的，计算完成后会自动释放
- 相比重新加载整个模型，这个临时峰值要小得多

## 显存占用对比表

| 方式 | 模型参数显存 | 激活值显存 | 总额外显存 |
|------|------------|-----------|-----------|
| **之前（重新加载）** | 6-8GB (3B) | ~0.5GB | **6.5-8.5GB** |
| **现在（引用）** | 0GB (已存在) | ~0.5GB | **~0.5GB** |

**节省显存：约 6-8GB（对于 3B 模型）**

## 注意事项

### 1. 模型状态管理

使用 FSDP 模型时需要注意：
- 模型可能处于训练模式（`train()`）或评估模式（`eval()`）
- 代码中已经设置了 `self.mi_model.eval()`，这是正确的

### 2. 设备一致性

- FSDP 模型会自动处理设备分配
- 输入数据需要放在正确的设备上
- 代码中已经正确处理了设备分配

### 3. 并发使用

如果同时进行：
- Actor 模型训练
- MI 计算（使用同一个 actor 模型）

可能会有一些显存竞争，但这是正常的，因为：
- 训练和 MI 计算不会同时进行（MI 计算在 rollout 阶段）
- FSDP 会自动管理参数的分片和通信

## 结论

✅ **使用 Worker 中的模型不会比之前占用更多显存**

实际上：
- **节省显存**：不重复加载模型，节省 6-8GB（3B 模型）
- **提高效率**：不需要重新加载模型，节省时间
- **保持一致性**：使用与训练相同的模型，结果更一致

## 建议

1. **优先使用 actor 模型**：如果可用，优先使用 `actor_module_fsdp`
2. **回退机制**：如果 worker 中没有模型，自动回退到从路径加载
3. **监控显存**：在训练过程中监控显存使用，确保没有意外峰值

